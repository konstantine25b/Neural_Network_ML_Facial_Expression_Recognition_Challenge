{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csfinq2paB5c"
      },
      "source": [
        "# experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfbFQvsvaB5d",
        "outputId": "e22f1ae8-faad-44ce-c739-279509553ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle wandb onnx -Uq\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FmpJtuUbReB",
        "outputId": "98fe7e26-7dbf-4b79-c436-26f9e81635cb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Z6-LioPebU7t"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Cog28bP7bWjG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSvyGJ5DbYbw",
        "outputId": "322e4d05-b6ed-4e98-e06b-0f415c927ebd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "challenges-in-representation-learning-facial-expression-recognition-challenge.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT63DsU3baPe",
        "outputId": "5addde94-dfb1-4fa2-c2f8-a355d0382f22"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "replace example_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: example_submission.csv  \n",
            "replace fer2013.tar.gz? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: fer2013.tar.gz          \n",
            "replace icml_face_data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: icml_face_data.csv      y\n",
            "y\n",
            "\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: test.csv                \n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: train.csv               yy\n",
            "y\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb onnx -Uq"
      ],
      "metadata": {
        "id": "dBorWgpubcCe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "rzRM5GCfbn9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import wandb"
      ],
      "metadata": {
        "id": "8XMa-Y3Fbp4s"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Device configuration\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # detect the GPU if any, if not use CPU, change cuda to mps if you have a mac\n",
        "print(\"Device available: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUM6OkuJbvTJ",
        "outputId": "19467125-d2a5-47fd-ce92-e3a325425b7f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsPDs2xwb4A0",
        "outputId": "e5b9dfe2-b4f0-4789-dada-d03853ad7dbe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training"
      ],
      "metadata": {
        "id": "-l7aC4uYcL2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n",
        "    'parameters': {\n",
        "        'learning_rate': {'values': [0.01, 0.005, 0.001, 0.0005]},\n",
        "        'batch_size': {'values': [32, 64, 128]},\n",
        "        'dropout_rate': {'values': [0.2, 0.3, 0.4]},\n",
        "        'weight_decay': {'values': [1e-4, 1e-5, 1e-6]},\n",
        "        'hidden_dim': {'values': [64, 128, 256]},\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "Y-COiFMbb8H2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"Facial_Expression_Recognition_3\")"
      ],
      "metadata": {
        "id": "ei06CK5ScKrd",
        "outputId": "bc07e162-1c55-4738-c21c-235e5a64b16d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: de1ahhg8\n",
            "Sweep URL: https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_3/sweeps/de1ahhg8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_train_df = pd.read_csv('train.csv')\n",
        "\n",
        "# First split: Create a test set (10% of original data)\n",
        "train_val_df, test_df = train_test_split(original_train_df, test_size=0.1,\n",
        "                                         random_state=42, stratify=original_train_df['emotion'])\n",
        "\n",
        "# Second split: Split remaining data into training (80%) and validation (20%)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.2,\n",
        "                                    random_state=42, stratify=train_val_df['emotion'])\n",
        "\n",
        "# Define emotion labels\n",
        "emotion_labels = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy',\n",
        "                  4: 'Sad', 5: 'Surprise', 6: 'Neutral'}"
      ],
      "metadata": {
        "id": "p8LsAQhVcNxx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original data size: {len(original_train_df)}\")\n",
        "print(f\"Training set size: {len(train_df)} ({len(train_df)/len(original_train_df)*100:.1f}%)\")\n",
        "print(f\"Validation set size: {len(val_df)} ({len(val_df)/len(original_train_df)*100:.1f}%)\")\n",
        "print(f\"Test set size: {len(test_df)} ({len(test_df)/len(original_train_df)*100:.1f}%)\")\n",
        "\n",
        "# Print class distribution in each set\n",
        "print(\"\\nEmotion distribution:\")\n",
        "for i, emotion in emotion_labels.items():\n",
        "    train_count = sum(train_df['emotion'] == i)\n",
        "    val_count = sum(val_df['emotion'] == i)\n",
        "    test_count = sum(test_df['emotion'] == i)\n",
        "    print(f\"  {emotion}: Train={train_count}, Val={val_count}, Test={test_count}\")\n"
      ],
      "metadata": {
        "id": "Pc9K4yvCcPzw",
        "outputId": "07156689-c5e3-441f-a7a2-3a30b68b7d4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data size: 28709\n",
            "Training set size: 20670 (72.0%)\n",
            "Validation set size: 5168 (18.0%)\n",
            "Test set size: 2871 (10.0%)\n",
            "\n",
            "Emotion distribution:\n",
            "  Angry: Train=2877, Val=719, Test=399\n",
            "  Disgust: Train=314, Val=78, Test=44\n",
            "  Fear: Train=2950, Val=737, Test=410\n",
            "  Happy: Train=5194, Val=1299, Test=722\n",
            "  Sad: Train=3477, Val=870, Test=483\n",
            "  Surprise: Train=2283, Val=571, Test=317\n",
            "  Neutral: Train=3575, Val=894, Test=496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FER2013Dataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        pixels = [int(pixel) for pixel in row['pixels'].split()]\n",
        "        image = np.array(pixels, dtype=np.uint8).reshape(48, 48)\n",
        "\n",
        "        # Convert to PIL Image for transforms\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = row['emotion']\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "Uy9RnEyhcTVk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Validation and test sets only need basic transformations\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "ORoG4iWicV0I"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FER2013Dataset(train_df, transform=train_transform)\n",
        "val_dataset = FER2013Dataset(val_df, transform=val_test_transform)\n",
        "test_dataset = FER2013Dataset(test_df, transform=val_test_transform)\n",
        "\n",
        "# Create a small subset for overfitting test (20 samples)\n",
        "indices = list(range(20))\n",
        "overfit_dataset = torch.utils.data.Subset(train_dataset, indices)"
      ],
      "metadata": {
        "id": "aAkoEDYtcg0f"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.3, hidden_dim=128):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, hidden_dim)\n",
        "        self.bn4 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        x = x.view(-1, 128 * 6 * 6)\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "hb9gCg1ich1e"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders(batch_size):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    overfit_loader = DataLoader(overfit_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "    return train_loader, val_loader, test_loader, overfit_loader\n"
      ],
      "metadata": {
        "id": "AdcwG_ZFdt9A"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(loader, model, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy, all_preds, all_labels\n"
      ],
      "metadata": {
        "id": "0ZbxQdMsdv9a"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test for 20 data overfit"
      ],
      "metadata": {
        "id": "-qqZvjiYd3u3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPKV5UexdznC"
      },
      "execution_count": 45,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}