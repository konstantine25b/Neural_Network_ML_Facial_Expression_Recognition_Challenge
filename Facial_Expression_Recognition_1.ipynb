{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMslV4VvJkWZdcusPg0u8UN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konstantine25b/Neural_Network_ML_Facial_Expression_Recognition_Challenge/blob/main/Facial_Expression_Recognition_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets goo Facial Expression Recognition"
      ],
      "metadata": {
        "id": "idj6qZy8em_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install"
      ],
      "metadata": {
        "id": "grrN3jXufCjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle wandb onnx -Uq\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCpzmsx9fCF-",
        "outputId": "d4d9f319-7c5c-4bdc-ce68-f0049e8402ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYzQOFRRfbq6",
        "outputId": "660bf959-9ebe-46b7-9f95-f35f033b6b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "xr41qAMsfeqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "AXheI1UefhRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVT9Q2Z0fi2J",
        "outputId": "b59bb457-f406-4423-9445-e50e04935847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 79% 226M/285M [00:00<00:00, 649MB/s] \n",
            "100% 285M/285M [00:00<00:00, 576MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ],
      "metadata": {
        "id": "ud9_1p0NghYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1f34d0-88bb-4fd9-8e76-cde373707848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb onnx -Uq"
      ],
      "metadata": {
        "id": "yQWxcTNki2aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wandb and conf staff"
      ],
      "metadata": {
        "id": "ZhU3pkCdjJuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# remove slow mirror from list of MNIST mirrors\n",
        "torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors\n",
        "                                      if not mirror.startswith(\"http://yann.lecun.com\")]"
      ],
      "metadata": {
        "id": "fkyQKur0jMb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "F0tWy6BWjWCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "oxvVVEDujYYp",
        "outputId": "89407dc3-04a6-4dd8-dd16-06a8523fe170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkonstantine25b\u001b[0m (\u001b[33mkonstantine25b-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "source": [
        "run = wandb.init(\n",
        "    entity=\"konstantine25b-free-university-of-tbilisi-\",\n",
        "    project=\"Facial_Expression_Recognition_1\",\n",
        "    config={\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"architecture\": \"Simple Neural Network (2 hidden layers, 64 neurons each, ReLU activation)\",\n",
        "        \"dataset\": \"Facial Expression Recognition Challenge\",\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 64,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"loss_function\": \"Cross-Entropy Loss\"\n",
        "    },\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "866h7Z-mkTKy",
        "outputId": "5c40cd54-dbcb-4e33-8f51-388d5730b7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250525_083117-c2dmi4go</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_1/runs/c2dmi4go' target=\"_blank\">twilight-energy-1</a></strong> to <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_1' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_1/runs/c2dmi4go' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_1/runs/c2dmi4go</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "import wandb\n",
        "import os\n",
        "import pandas as pd # Assuming you might need pandas for data loading\n",
        "\n",
        "# Assuming the data is in a directory named 'train' and 'test' after unzipping\n",
        "# You might need to adjust the paths based on how the data is structured\n",
        "\n",
        "# Example: Load data using pandas if you have a CSV file with labels/metadata\n",
        "# data_dir = \"path/to/your/unzipped/data\" # Replace with the actual path\n",
        "# train_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
        "# test_df = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\n",
        "\n",
        "# Create a wandb artifact\n",
        "# Reference [1] explains how to create an artifact with a type and project\n",
        "raw_data_artifact = wandb.Artifact(\n",
        "    name=\"facial-expression-dataset\",\n",
        "    type=\"dataset\",\n",
        "    description=\"Facial Expression Recognition Challenge Dataset\"\n",
        ")\n",
        "\n",
        "# Add data to the artifact\n",
        "# You would typically add the directory containing your images and any metadata files\n",
        "# raw_data_artifact.add_dir(data_dir) # Add the entire data directory\n",
        "\n",
        "# If you have individual files, you can add them like this:\n",
        "# raw_data_artifact.add_file(os.path.join(data_dir, \"train.csv\"))\n",
        "# raw_data_artifact.add_file(os.path.join(data_dir, \"test.csv\"))\n",
        "# You will need to adapt this part based on the actual file structure of the downloaded data\n",
        "\n",
        "# Log the artifact to the current run\n",
        "wandb.log_artifact(raw_data_artifact)\n",
        "\n",
        "print(\"Data loaded and logged as a wandb artifact.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1RSCWlJlIDZ",
        "outputId": "e4981b2f-cefb-45d6-ccb3-f24e86528cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and logged as a wandb artifact.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "artifact = run.use_artifact('facial-expression-dataset:latest')\n",
        "\n",
        "# Download the data from the artifact\n",
        "# You might need to specify a directory to download to\n",
        "data_dir = artifact.download()\n"
      ],
      "metadata": {
        "id": "34pLLU1clltO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "dib-KIMJlwoH",
        "outputId": "dce83ad8-52c8-4a9c-f4c5-53be663ea84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a63cb2d2b0d8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}