{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konstantine25b/Neural_Network_ML_Facial_Expression_Recognition_Challenge/blob/main/Facial_Expression_Recognition_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbeQZRdyRlaN"
      },
      "outputs": [],
      "source": [
        "# Experiment 7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle wandb onnx -Uq\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcJIxxm-RmLF",
        "outputId": "c79fc8f7-df10-425b-b94b-7688d9c15ef5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/17.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/17.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/17.6 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m13.0/17.6 MB\u001b[0m \u001b[31m136.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx_8PXOqRlaO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "NCWu6N_rRtdq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "r1z9PIJ1Ruod"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "SBi3ibr6Rv89"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR8SLwjOR0U1",
        "outputId": "bda4626e-d64e-4e08-9499-37708ab413e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 88% 251M/285M [00:00<00:00, 773MB/s] \n",
            "100% 285M/285M [00:00<00:00, 818MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsyrMUI4R4WD",
        "outputId": "a7f0f701-42f9-41b1-ad83-46ec48050d20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb onnx -Uq"
      ],
      "metadata": {
        "id": "d1ylEB48R5dT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "yHx2eYZGR8sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ez97D8rqR6xp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mlr64hqAR_C-",
        "outputId": "5b7791d3-4efd-400e-9777-666488046427"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "FKH2fNQxSA4G",
        "outputId": "33426c9f-cd8a-4aba-a2b0-5664a3944daa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkonstantine25b\u001b[0m (\u001b[33mkonstantine25b-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FER2013Dataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        emotion = self.data.iloc[idx]['emotion']\n",
        "\n",
        "        image = np.array([int(pixel) for pixel in pixels.split()]).reshape(48, 48)\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = torch.FloatTensor(image).unsqueeze(0)\n",
        "\n",
        "        return image, emotion"
      ],
      "metadata": {
        "id": "Ghit0PiRSCYe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms():\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Pad(4),\n",
        "        transforms.RandomCrop(48),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    val_test_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_test_transform"
      ],
      "metadata": {
        "id": "SIZque0pSIgH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_val_loaders(csv_file, batch_size=64, train_split=0.8):\n",
        "    train_transform, val_transform = get_transforms()\n",
        "\n",
        "    full_dataset = FER2013Dataset(csv_file, transform=None)\n",
        "\n",
        "    train_size = int(train_split * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(\n",
        "        full_dataset, [train_size, val_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    train_dataset.dataset.transform = train_transform\n",
        "    val_dataset.dataset.transform = val_transform\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "pfSbaNG4SN9M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_loader(csv_file, batch_size=64):\n",
        "    _, test_transform = get_transforms()\n",
        "\n",
        "    test_dataset = FER2013Dataset(csv_file, transform=test_transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return test_loader"
      ],
      "metadata": {
        "id": "fnkPPz84SWXJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Aw6znviPSdQL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleFacialExpressionResNet(nn.Module):\n",
        "    def __init__(self, num_classes=7, dropout_rate=0.3):\n",
        "        super(SimpleFacialExpressionResNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.layer1 = BasicResidualBlock(32, 32, stride=1)\n",
        "        self.layer2 = BasicResidualBlock(32, 64, stride=2)\n",
        "        self.layer3 = BasicResidualBlock(64, 128, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "5QymSPzoSfeN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_overfitting():\n",
        "    print(\"Testing simple ResNet architecture with overfitting on small dataset...\")\n",
        "\n",
        "    model = SimpleFacialExpressionResNet(dropout_rate=0.0).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_loader, _ = create_train_val_loaders('train.csv', batch_size=32)\n",
        "\n",
        "    small_batch = []\n",
        "    for i, (data, target) in enumerate(train_loader):\n",
        "        small_batch.extend(list(zip(data, target)))\n",
        "        if len(small_batch) >= 20:\n",
        "            break\n",
        "\n",
        "    small_batch = small_batch[:20]\n",
        "\n",
        "    for epoch in range(30):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for data, target in small_batch:\n",
        "            data, target = data.unsqueeze(0).to(device), torch.tensor([target]).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "\n",
        "        accuracy = 100. * correct / len(small_batch)\n",
        "        avg_loss = total_loss / len(small_batch)\n",
        "\n",
        "        print(f\"Overfit Epoch {epoch+1}/30, Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%\")\n",
        "\n",
        "        if accuracy >= 95.0:\n",
        "            print(\"Simple ResNet can overfit successfully!\")\n",
        "            break\n",
        "\n",
        "    print(\"Overfitting test completed.\\n\")\n"
      ],
      "metadata": {
        "id": "0L5BRAgvSj5d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(loader, model, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "    return total_loss / len(loader), 100. * correct / total"
      ],
      "metadata": {
        "id": "1MRN7x68Slwa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(config=None):\n",
        "    with wandb.init(project=\"Facial_Expression_Recognition_6\", config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        model = SimpleFacialExpressionResNet(dropout_rate=config.dropout_rate).to(device)\n",
        "        train_loader, val_loader = create_train_val_loaders('train.csv', config.batch_size)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
        "\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
        "        )\n",
        "\n",
        "        best_val_acc = 0\n",
        "        patience_counter = 0\n",
        "\n",
        "        wandb.watch(model, log=\"gradients\", log_freq=100)\n",
        "\n",
        "        for epoch in range(config.epochs):\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.epochs} [Train]')\n",
        "\n",
        "            for batch_idx, (data, target) in enumerate(progress_bar):\n",
        "                data, target = data.to(device), target.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                output = model(data)\n",
        "                loss = criterion(output, target)\n",
        "                loss.backward()\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                pred = output.argmax(dim=1)\n",
        "                train_correct += pred.eq(target).sum().item()\n",
        "                train_total += target.size(0)\n",
        "\n",
        "                if batch_idx % 50 == 0:\n",
        "                    wandb.log({\n",
        "                        \"batch_loss\": loss.item(),\n",
        "                        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "                        \"epoch\": epoch\n",
        "                    })\n",
        "\n",
        "                progress_bar.set_postfix({\n",
        "                    'loss': f'{loss.item():.3f}',\n",
        "                    'acc': f'{100.*train_correct/train_total:.1f}%'\n",
        "                })\n",
        "\n",
        "            train_acc = 100. * train_correct / train_total\n",
        "            train_loss = train_loss / len(train_loader)\n",
        "\n",
        "            val_loss, val_acc = compute_loss(val_loader, model, criterion, device)\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch,\n",
        "                \"train_loss\": train_loss,\n",
        "                \"train_accuracy\": train_acc,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_accuracy\": val_acc,\n",
        "                \"train_val_gap\": train_acc - val_acc\n",
        "            })\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{config.epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Gap: {train_acc-val_acc:.2f}%\")\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "\n",
        "                model_artifact = wandb.Artifact(\n",
        "                    name=f\"best_model_{wandb.run.name}\",\n",
        "                    type=\"model\",\n",
        "                    description=f\"Best simple ResNet model with validation accuracy: {val_acc:.2f}%\"\n",
        "                )\n",
        "\n",
        "                model_save_dict = {\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'model_config': {\n",
        "                        'num_classes': 7,\n",
        "                        'dropout_rate': config.dropout_rate\n",
        "                    },\n",
        "                    'training_config': dict(config),\n",
        "                    'val_accuracy': val_acc,\n",
        "                    'epoch': epoch,\n",
        "                    'model_architecture': 'SimpleFacialExpressionResNet'\n",
        "                }\n",
        "\n",
        "                torch.save(model_save_dict, \"best_model.pth\")\n",
        "\n",
        "                model_artifact.add_file(\"best_model.pth\")\n",
        "                wandb.log_artifact(model_artifact)\n",
        "\n",
        "                print(f\"New best model saved with validation accuracy: {val_acc:.2f}%\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= config.patience:\n",
        "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                break\n",
        "\n",
        "        wandb.log({\n",
        "            \"best_val_accuracy\": best_val_acc\n",
        "        })\n",
        "\n",
        "        print(f\"Training completed. Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "        return best_val_acc\n"
      ],
      "metadata": {
        "id": "RPa1VfORSoPb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_on_testset(model_artifact_path, test_csv_file, batch_size=64):\n",
        "    checkpoint = torch.load(model_artifact_path, map_location=device)\n",
        "\n",
        "    model_config = checkpoint['model_config']\n",
        "    model = SimpleFacialExpressionResNet(\n",
        "        num_classes=model_config['num_classes'],\n",
        "        dropout_rate=model_config['dropout_rate']\n",
        "    ).to(device)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    test_loader = create_test_loader(test_csv_file, batch_size)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loss, test_acc = compute_loss(test_loader, model, criterion, device)\n",
        "\n",
        "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_targets, all_preds, target_names=emotion_labels))\n",
        "\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=emotion_labels, yticklabels=emotion_labels)\n",
        "    plt.title('Confusion Matrix - Facial Expression Recognition (Simple ResNet)')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return test_acc, all_preds, all_targets"
      ],
      "metadata": {
        "id": "ojWKRjzfSqpB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "        'name': 'best_val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'learning_rate': {\n",
        "            'distribution': 'log_uniform_values',\n",
        "            'min': 0.0005,\n",
        "            'max': 0.005\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'dropout_rate': {\n",
        "            'distribution': 'uniform',\n",
        "            'min': 0.3,\n",
        "            'max': 0.6\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'distribution': 'log_uniform_values',\n",
        "            'min': 1e-4,\n",
        "            'max': 1e-2\n",
        "        },\n",
        "        'label_smoothing': {\n",
        "            'distribution': 'uniform',\n",
        "            'min': 0.1,\n",
        "            'max': 0.3\n",
        "        },\n",
        "        'epochs': {\n",
        "            'value': 25\n",
        "        },\n",
        "        'patience': {\n",
        "            'value': 4\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "idyiqZi3SuhC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_overfitting()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6btW3u3SzIa",
        "outputId": "1b418012-6a71-4699-a7f0-a33b0a288d90"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing simple ResNet architecture with overfitting on small dataset...\n",
            "Overfit Epoch 1/30, Loss: 1.9199, Acc: 25.00%\n",
            "Overfit Epoch 2/30, Loss: 1.6423, Acc: 40.00%\n",
            "Overfit Epoch 3/30, Loss: 1.5754, Acc: 40.00%\n",
            "Overfit Epoch 4/30, Loss: 1.5327, Acc: 40.00%\n",
            "Overfit Epoch 5/30, Loss: 1.4881, Acc: 40.00%\n",
            "Overfit Epoch 6/30, Loss: 1.4460, Acc: 40.00%\n",
            "Overfit Epoch 7/30, Loss: 1.4089, Acc: 40.00%\n",
            "Overfit Epoch 8/30, Loss: 1.3815, Acc: 40.00%\n",
            "Overfit Epoch 9/30, Loss: 1.3236, Acc: 40.00%\n",
            "Overfit Epoch 10/30, Loss: 1.2618, Acc: 40.00%\n",
            "Overfit Epoch 11/30, Loss: 1.2136, Acc: 40.00%\n",
            "Overfit Epoch 12/30, Loss: 1.1741, Acc: 50.00%\n",
            "Overfit Epoch 13/30, Loss: 1.1043, Acc: 55.00%\n",
            "Overfit Epoch 14/30, Loss: 1.0402, Acc: 55.00%\n",
            "Overfit Epoch 15/30, Loss: 0.9781, Acc: 60.00%\n",
            "Overfit Epoch 16/30, Loss: 0.9043, Acc: 60.00%\n",
            "Overfit Epoch 17/30, Loss: 0.8446, Acc: 60.00%\n",
            "Overfit Epoch 18/30, Loss: 0.7780, Acc: 80.00%\n",
            "Overfit Epoch 19/30, Loss: 0.7111, Acc: 90.00%\n",
            "Overfit Epoch 20/30, Loss: 0.6520, Acc: 90.00%\n",
            "Overfit Epoch 21/30, Loss: 0.5895, Acc: 100.00%\n",
            "Simple ResNet can overfit successfully!\n",
            "Overfitting test completed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"Facial_Expression_Recognition_6\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCG1rS_XS6iY",
        "outputId": "69bbb0dd-8455-408e-a25c-9a8ac924717b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 3ss2257j\n",
            "Sweep URL: https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running simple ResNet hyperparameter sweep...\")\n",
        "wandb.agent(sweep_id, train_model, count=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7wV4d-V3TPWl",
        "outputId": "8f3612b1-a075-441c-fbf0-36e3022e9112"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running simple ResNet hyperparameter sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p5yjd0pg with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4136772971359127\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlabel_smoothing: 0.29189418822005997\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0013036118162858769\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.004210023573569834\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'Facial_Expression_Recognition_6' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250601_114306-p5yjd0pg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/p5yjd0pg' target=\"_blank\">wild-sweep-1</a></strong> to <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/p5yjd0pg' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/p5yjd0pg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25 [Train]: 100%|██████████| 180/180 [00:22<00:00,  7.98it/s, loss=1.895, acc=28.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Train Loss: 1.8522, Train Acc: 28.55%, Val Loss: 1.8008, Val Acc: 33.30%, Gap: -4.75%\n",
            "New best model saved with validation accuracy: 33.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/25 [Train]: 100%|██████████| 180/180 [00:22<00:00,  7.99it/s, loss=1.769, acc=37.2%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/25, Train Loss: 1.7785, Train Acc: 37.17%, Val Loss: 1.9331, Val Acc: 24.36%, Gap: 12.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/25 [Train]: 100%|██████████| 180/180 [00:24<00:00,  7.40it/s, loss=1.553, acc=43.3%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/25, Train Loss: 1.7170, Train Acc: 43.34%, Val Loss: 1.7245, Val Acc: 42.70%, Gap: 0.63%\n",
            "New best model saved with validation accuracy: 42.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/25 [Train]: 100%|██████████| 180/180 [00:24<00:00,  7.25it/s, loss=1.603, acc=47.2%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/25, Train Loss: 1.6790, Train Acc: 47.24%, Val Loss: 1.6741, Val Acc: 47.70%, Gap: -0.46%\n",
            "New best model saved with validation accuracy: 47.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/25 [Train]: 100%|██████████| 180/180 [00:24<00:00,  7.28it/s, loss=1.642, acc=50.3%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/25, Train Loss: 1.6466, Train Acc: 50.32%, Val Loss: 1.6779, Val Acc: 47.07%, Gap: 3.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/25 [Train]: 100%|██████████| 180/180 [00:25<00:00,  7.18it/s, loss=1.561, acc=52.7%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/25, Train Loss: 1.6211, Train Acc: 52.68%, Val Loss: 1.7332, Val Acc: 42.60%, Gap: 10.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/25 [Train]: 100%|██████████| 180/180 [00:24<00:00,  7.20it/s, loss=1.627, acc=54.8%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/25, Train Loss: 1.5994, Train Acc: 54.77%, Val Loss: 1.6495, Val Acc: 50.21%, Gap: 4.56%\n",
            "New best model saved with validation accuracy: 50.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/25 [Train]: 100%|██████████| 180/180 [00:23<00:00,  7.59it/s, loss=1.549, acc=56.2%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/25, Train Loss: 1.5845, Train Acc: 56.18%, Val Loss: 1.6684, Val Acc: 49.90%, Gap: 6.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/25 [Train]: 100%|██████████| 180/180 [00:22<00:00,  7.87it/s, loss=1.551, acc=58.4%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/25, Train Loss: 1.5632, Train Acc: 58.45%, Val Loss: 1.5966, Val Acc: 54.98%, Gap: 3.47%\n",
            "New best model saved with validation accuracy: 54.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/25 [Train]: 100%|██████████| 180/180 [00:22<00:00,  7.86it/s, loss=1.620, acc=60.2%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/25, Train Loss: 1.5440, Train Acc: 60.16%, Val Loss: 1.6734, Val Acc: 48.85%, Gap: 11.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/25 [Train]: 100%|██████████| 180/180 [00:22<00:00,  7.98it/s, loss=1.655, acc=62.6%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/25, Train Loss: 1.5205, Train Acc: 62.61%, Val Loss: 1.6098, Val Acc: 54.09%, Gap: 8.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/25 [Train]: 100%|██████████| 180/180 [00:23<00:00,  7.75it/s, loss=1.626, acc=64.6%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/25, Train Loss: 1.5003, Train Acc: 64.59%, Val Loss: 1.6776, Val Acc: 51.43%, Gap: 13.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/25 [Train]: 100%|██████████| 180/180 [00:23<00:00,  7.55it/s, loss=1.586, acc=66.7%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/25, Train Loss: 1.4794, Train Acc: 66.74%, Val Loss: 1.6710, Val Acc: 52.63%, Gap: 14.11%\n",
            "Early stopping triggered after 13 epochs\n",
            "Training completed. Best validation accuracy: 54.98%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>█▇▆▆▅▆▅▅▅▅▄▅▄▄▅▄▄▄▄▄▄▃▂▄▃▃▂▃▃▂▂▂▂▃▂▂▁▁▁▂</td></tr><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▇▅▅▄▄▃▃▃▂▂▁▁</td></tr><tr><td>train_val_gap</td><td>▁█▃▃▄▇▄▅▄▇▆██</td></tr><tr><td>val_accuracy</td><td>▃▁▅▆▆▅▇▇█▇█▇▇</td></tr><tr><td>val_loss</td><td>▅█▄▃▃▄▂▂▁▃▁▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>1.51868</td></tr><tr><td>best_val_accuracy</td><td>54.98084</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>learning_rate</td><td>0.0013</td></tr><tr><td>train_accuracy</td><td>66.73923</td></tr><tr><td>train_loss</td><td>1.4794</td></tr><tr><td>train_val_gap</td><td>14.10949</td></tr><tr><td>val_accuracy</td><td>52.62975</td></tr><tr><td>val_loss</td><td>1.67104</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wild-sweep-1</strong> at: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/p5yjd0pg' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/p5yjd0pg</a><br> View project at: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6</a><br>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250601_114306-p5yjd0pg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oj5u2i8s with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.36102178971367016\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlabel_smoothing: 0.2236615416461067\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00408643259183888\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0022730632370258973\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'Facial_Expression_Recognition_6' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250601_114940-oj5u2i8s</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/oj5u2i8s' target=\"_blank\">wise-sweep-2</a></strong> to <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/oj5u2i8s' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/oj5u2i8s</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.74it/s, loss=1.779, acc=26.9%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Train Loss: 1.8520, Train Acc: 26.86%, Val Loss: 1.8290, Val Acc: 26.96%, Gap: -0.09%\n",
            "New best model saved with validation accuracy: 26.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.73it/s, loss=1.742, acc=34.4%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/25, Train Loss: 1.7728, Train Acc: 34.37%, Val Loss: 1.8465, Val Acc: 33.63%, Gap: 0.74%\n",
            "New best model saved with validation accuracy: 33.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.30it/s, loss=1.618, acc=42.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/25, Train Loss: 1.6816, Train Acc: 42.49%, Val Loss: 1.6576, Val Acc: 45.28%, Gap: -2.79%\n",
            "New best model saved with validation accuracy: 45.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.60it/s, loss=1.531, acc=47.9%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/25, Train Loss: 1.6173, Train Acc: 47.88%, Val Loss: 1.5750, Val Acc: 51.24%, Gap: -3.36%\n",
            "New best model saved with validation accuracy: 51.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.62it/s, loss=1.613, acc=51.3%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/25, Train Loss: 1.5742, Train Acc: 51.34%, Val Loss: 1.5762, Val Acc: 50.26%, Gap: 1.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.58it/s, loss=1.446, acc=54.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/25, Train Loss: 1.5315, Train Acc: 54.51%, Val Loss: 1.5294, Val Acc: 54.42%, Gap: 0.09%\n",
            "New best model saved with validation accuracy: 54.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.53it/s, loss=1.512, acc=57.0%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/25, Train Loss: 1.5004, Train Acc: 56.97%, Val Loss: 1.7034, Val Acc: 43.83%, Gap: 13.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.56it/s, loss=1.487, acc=59.1%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/25, Train Loss: 1.4711, Train Acc: 59.08%, Val Loss: 1.5228, Val Acc: 55.31%, Gap: 3.77%\n",
            "New best model saved with validation accuracy: 55.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.45it/s, loss=1.419, acc=61.2%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/25, Train Loss: 1.4474, Train Acc: 61.17%, Val Loss: 1.4939, Val Acc: 56.91%, Gap: 4.26%\n",
            "New best model saved with validation accuracy: 56.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.68it/s, loss=1.463, acc=63.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/25, Train Loss: 1.4189, Train Acc: 63.53%, Val Loss: 1.4767, Val Acc: 58.85%, Gap: 4.68%\n",
            "New best model saved with validation accuracy: 58.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.66it/s, loss=1.272, acc=66.2%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/25, Train Loss: 1.3867, Train Acc: 66.16%, Val Loss: 1.5320, Val Acc: 56.20%, Gap: 9.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.47it/s, loss=1.336, acc=68.4%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/25, Train Loss: 1.3564, Train Acc: 68.38%, Val Loss: 1.5348, Val Acc: 55.78%, Gap: 12.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.60it/s, loss=1.255, acc=71.1%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/25, Train Loss: 1.3233, Train Acc: 71.12%, Val Loss: 1.5377, Val Acc: 55.76%, Gap: 15.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.64it/s, loss=1.193, acc=74.1%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/25, Train Loss: 1.2872, Train Acc: 74.11%, Val Loss: 1.5096, Val Acc: 57.87%, Gap: 16.24%\n",
            "Early stopping triggered after 14 epochs\n",
            "Training completed. Best validation accuracy: 58.85%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▇█▇▇▇▇█▅▆▅▅▄▅▄▅▄▄▃▃▅▄▃▄▂▃▄▂▄▂▂▃▂▂▂▃▂▂▁▁▁</td></tr><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▄▃▃▃▂▂▁▁</td></tr><tr><td>train_val_gap</td><td>▂▂▁▁▃▂▇▄▄▄▆▇██</td></tr><tr><td>val_accuracy</td><td>▁▂▅▆▆▇▅▇██▇▇▇█</td></tr><tr><td>val_loss</td><td>██▄▃▃▂▅▂▁▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>1.29204</td></tr><tr><td>best_val_accuracy</td><td>58.84709</td></tr><tr><td>epoch</td><td>13</td></tr><tr><td>learning_rate</td><td>0.00409</td></tr><tr><td>train_accuracy</td><td>74.11068</td></tr><tr><td>train_loss</td><td>1.28722</td></tr><tr><td>train_val_gap</td><td>16.23886</td></tr><tr><td>val_accuracy</td><td>57.87182</td></tr><tr><td>val_loss</td><td>1.50959</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wise-sweep-2</strong> at: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/oj5u2i8s' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/oj5u2i8s</a><br> View project at: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6</a><br>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250601_114940-oj5u2i8s/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ni7fx05w with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.39279270235612185\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlabel_smoothing: 0.18228636891748304\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006116992836961315\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.002491413616278195\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'Facial_Expression_Recognition_6' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250601_115711-ni7fx05w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w' target=\"_blank\">sweepy-sweep-3</a></strong> to <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.56it/s, loss=1.754, acc=29.3%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Train Loss: 1.8143, Train Acc: 29.34%, Val Loss: 1.7808, Val Acc: 32.48%, Gap: -3.14%\n",
            "New best model saved with validation accuracy: 32.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.53it/s, loss=1.746, acc=36.9%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/25, Train Loss: 1.7214, Train Acc: 36.92%, Val Loss: 1.8113, Val Acc: 34.20%, Gap: 2.72%\n",
            "New best model saved with validation accuracy: 34.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.58it/s, loss=1.708, acc=42.9%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/25, Train Loss: 1.6450, Train Acc: 42.89%, Val Loss: 1.6027, Val Acc: 46.13%, Gap: -3.24%\n",
            "New best model saved with validation accuracy: 46.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.53it/s, loss=1.574, acc=46.8%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/25, Train Loss: 1.5936, Train Acc: 46.79%, Val Loss: 1.5975, Val Acc: 45.75%, Gap: 1.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.54it/s, loss=1.522, acc=49.6%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/25, Train Loss: 1.5542, Train Acc: 49.58%, Val Loss: 1.5756, Val Acc: 48.26%, Gap: 1.33%\n",
            "New best model saved with validation accuracy: 48.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.48it/s, loss=1.566, acc=51.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/25, Train Loss: 1.5210, Train Acc: 51.53%, Val Loss: 1.5521, Val Acc: 50.12%, Gap: 1.40%\n",
            "New best model saved with validation accuracy: 50.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.53it/s, loss=1.445, acc=53.8%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/25, Train Loss: 1.4908, Train Acc: 53.76%, Val Loss: 1.5254, Val Acc: 51.31%, Gap: 2.46%\n",
            "New best model saved with validation accuracy: 51.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.52it/s, loss=1.505, acc=56.3%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/25, Train Loss: 1.4585, Train Acc: 56.33%, Val Loss: 1.5688, Val Acc: 50.26%, Gap: 6.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.58it/s, loss=1.399, acc=57.8%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/25, Train Loss: 1.4330, Train Acc: 57.82%, Val Loss: 1.4982, Val Acc: 53.71%, Gap: 4.11%\n",
            "New best model saved with validation accuracy: 53.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.67it/s, loss=1.430, acc=60.4%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/25, Train Loss: 1.4014, Train Acc: 60.38%, Val Loss: 1.5851, Val Acc: 49.09%, Gap: 11.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.62it/s, loss=1.301, acc=62.2%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/25, Train Loss: 1.3703, Train Acc: 62.22%, Val Loss: 1.4942, Val Acc: 54.02%, Gap: 8.19%\n",
            "New best model saved with validation accuracy: 54.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.59it/s, loss=1.415, acc=64.5%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/25, Train Loss: 1.3409, Train Acc: 64.47%, Val Loss: 1.5949, Val Acc: 47.67%, Gap: 16.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.59it/s, loss=1.352, acc=67.0%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/25, Train Loss: 1.3101, Train Acc: 66.96%, Val Loss: 1.5456, Val Acc: 52.07%, Gap: 14.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.44it/s, loss=1.329, acc=69.4%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/25, Train Loss: 1.2751, Train Acc: 69.36%, Val Loss: 1.5202, Val Acc: 54.13%, Gap: 15.24%\n",
            "New best model saved with validation accuracy: 54.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.58it/s, loss=1.230, acc=71.7%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/25, Train Loss: 1.2438, Train Acc: 71.68%, Val Loss: 1.5806, Val Acc: 53.03%, Gap: 18.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.59it/s, loss=1.199, acc=77.3%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/25, Train Loss: 1.1675, Train Acc: 77.30%, Val Loss: 1.5587, Val Acc: 52.54%, Gap: 24.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/25 [Train]: 100%|██████████| 359/359 [00:27<00:00, 13.12it/s, loss=1.253, acc=79.9%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/25, Train Loss: 1.1365, Train Acc: 79.88%, Val Loss: 1.5670, Val Acc: 52.46%, Gap: 27.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.48it/s, loss=1.221, acc=82.0%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/25, Train Loss: 1.1117, Train Acc: 82.00%, Val Loss: 1.5407, Val Acc: 54.60%, Gap: 27.40%\n",
            "New best model saved with validation accuracy: 54.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.59it/s, loss=1.150, acc=83.0%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/25, Train Loss: 1.0920, Train Acc: 83.05%, Val Loss: 1.5879, Val Acc: 52.11%, Gap: 30.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.49it/s, loss=1.020, acc=86.9%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/25, Train Loss: 1.0460, Train Acc: 86.86%, Val Loss: 1.5686, Val Acc: 54.48%, Gap: 32.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.52it/s, loss=1.059, acc=87.7%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/25, Train Loss: 1.0348, Train Acc: 87.71%, Val Loss: 1.5927, Val Acc: 53.73%, Gap: 33.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/25 [Train]: 100%|██████████| 359/359 [00:26<00:00, 13.47it/s, loss=1.036, acc=88.8%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/25, Train Loss: 1.0206, Train Acc: 88.84%, Val Loss: 1.5795, Val Acc: 53.85%, Gap: 34.99%\n",
            "Early stopping triggered after 22 epochs\n",
            "Training completed. Best validation accuracy: 54.60%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>█████▇▇▆▇▆▅▆▄▅▇▆▅▆▄▅▄▄▄▄▅▃▄▃▃▂▂▁▂▂▂▂▂▁▁▂</td></tr><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>learning_rate</td><td>█████████████████████████▃▃▃▃▃▃▃▃▃▃▃▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▅▅▄▄▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train_val_gap</td><td>▁▂▁▂▂▂▂▃▂▄▃▅▄▄▅▆▇▇▇███</td></tr><tr><td>val_accuracy</td><td>▁▂▅▅▆▇▇▇█▆█▆▇██▇▇█▇███</td></tr><tr><td>val_loss</td><td>▇█▃▃▃▂▂▃▁▃▁▃▂▂▃▂▃▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.98143</td></tr><tr><td>best_val_accuracy</td><td>54.5977</td></tr><tr><td>epoch</td><td>21</td></tr><tr><td>learning_rate</td><td>0.00015</td></tr><tr><td>train_accuracy</td><td>88.83616</td></tr><tr><td>train_loss</td><td>1.02059</td></tr><tr><td>train_val_gap</td><td>34.98732</td></tr><tr><td>val_accuracy</td><td>53.84883</td></tr><tr><td>val_loss</td><td>1.57951</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sweepy-sweep-3</strong> at: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w</a><br> View project at: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250601_115711-ni7fx05w/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api = wandb.Api()\n",
        "runs = api.runs(\"konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6\")\n",
        "\n",
        "best_run = None\n",
        "best_val_acc = 0"
      ],
      "metadata": {
        "id": "E4XYlbQeZf8Q"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for run in runs:\n",
        "    if run.state == \"finished\" and \"best_val_accuracy\" in run.summary:\n",
        "        val_acc = run.summary[\"best_val_accuracy\"]\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_run = run\n"
      ],
      "metadata": {
        "id": "VuFTkrpKZjEF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if best_run:\n",
        "    print(f\"\\nBest run: {best_run.name}\")\n",
        "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "    print(f\"Best hyperparameters: {best_run.config}\")\n",
        "\n",
        "    # Download the artifact\n",
        "    artifacts = api.artifact(f\"konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/best_model_{best_run.name}:latest\")\n",
        "    download_path = artifacts.download()\n",
        "\n",
        "    # Check what was actually downloaded\n",
        "    print(f\"Downloaded to: {download_path}\")\n",
        "\n",
        "    # Find the correct path to the model file\n",
        "    import os\n",
        "    model_file_path = None\n",
        "\n",
        "    # Check in the download directory\n",
        "    if os.path.exists(os.path.join(download_path, \"best_model.pth\")):\n",
        "        model_file_path = os.path.join(download_path, \"best_model.pth\")\n",
        "    # Check in current directory\n",
        "    elif os.path.exists(\"best_model.pth\"):\n",
        "        model_file_path = \"best_model.pth\"\n",
        "    # Search recursively\n",
        "    else:\n",
        "        for root, dirs, files in os.walk(\".\"):\n",
        "            if \"best_model.pth\" in files:\n",
        "                model_file_path = os.path.join(root, \"best_model.pth\")\n",
        "                break\n",
        "\n",
        "    if model_file_path and os.path.exists(model_file_path):\n",
        "        print(f\"Found model file at: {model_file_path}\")\n",
        "\n",
        "        # Create final artifact with correct path\n",
        "        final_artifact = wandb.Artifact(\n",
        "            name=\"final_best_resnet_model\",\n",
        "            type=\"model\",\n",
        "            description=f\"Final best ResNet model with {best_val_acc:.2f}% validation accuracy\"\n",
        "        )\n",
        "        final_artifact.add_file(model_file_path)\n",
        "\n",
        "        # Upload the final artifact\n",
        "        with wandb.init(project=\"Facial_Expression_Recognition_6\", name=\"final_model_upload\"):\n",
        "            wandb.log_artifact(final_artifact)\n",
        "            wandb.log({\n",
        "                \"final_best_val_accuracy\": best_val_acc,\n",
        "                \"model_architecture\": \"ResNet\",\n",
        "                \"ready_for_testing\": True\n",
        "            })\n",
        "\n",
        "        print(f\"\\nFinal model uploaded to wandb as 'final_best_resnet_model'\")\n",
        "        print(\"You can now load this model in the future for testing on any dataset!\")\n",
        "\n",
        "        print(\"\\nTo test on a different dataset in the future, use:\")\n",
        "        print(\"evaluate_model_on_testset('path_to_downloaded_model.pth', 'your_test_dataset.csv')\")\n",
        "\n",
        "    else:\n",
        "        print(\"Error: Could not find the downloaded model file!\")\n",
        "        print(\"Files in current directory:\")\n",
        "        for item in os.listdir(\".\"):\n",
        "            print(f\"  {item}\")\n",
        "\n",
        "else:\n",
        "    print(\"No successful runs found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "cOyL2fHeZk3w",
        "outputId": "54ea15cc-ac0f-4829-8e38-e8c3bc11e66f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best run: wise-sweep-2\n",
            "Best validation accuracy: 58.85%\n",
            "Best hyperparameters: {'epochs': 25, 'patience': 4, 'batch_size': 64, 'dropout_rate': 0.36102178971367016, 'weight_decay': 0.0022730632370258973, 'learning_rate': 0.00408643259183888, 'label_smoothing': 0.2236615416461067}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded to: /content/artifacts/best_model_wise-sweep-2:v7\n",
            "Found model file at: /content/artifacts/best_model_wise-sweep-2:v7/best_model.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'Facial_Expression_Recognition_6' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250601_121057-ni7fx05w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w' target=\"_blank\">final_model_upload</a></strong> to <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/sweeps/3ss2257j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>final_best_val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>final_best_val_accuracy</td><td>58.84709</td></tr><tr><td>model_architecture</td><td>ResNet</td></tr><tr><td>ready_for_testing</td><td>True</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">final_model_upload</strong> at: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6/runs/ni7fx05w</a><br> View project at: <a href='https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6' target=\"_blank\">https://wandb.ai/konstantine25b-free-university-of-tbilisi-/Facial_Expression_Recognition_6</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250601_121057-ni7fx05w/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final model uploaded to wandb as 'final_best_resnet_model'\n",
            "You can now load this model in the future for testing on any dataset!\n",
            "\n",
            "To test on a different dataset in the future, use:\n",
            "evaluate_model_on_testset('path_to_downloaded_model.pth', 'your_test_dataset.csv')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}